"""AI Workflow module for paper analysis and article generation.

This module implements a multi-phase AI workflow using Prompt-Chaining
and Evaluator-Optimizer patterns:

Phase 1: Paper Analysis (論文読む係のLLM)
Phase 2: Article Generation (記事書く係のLLM)
Phase 3: Evaluation & Improvement Loop (評価用LLM + Evaluator-Optimizer)
Phase 4: Whole Article Evaluation & Improvement (記事全体評価用LLM)
Phase 5: Section Heading Generation (見出し生成用LLM)
Phase 6: Article Title Generation (タイトル生成用LLM)
"""

import logging

from src.utils.config import load_config
from src.utils.openai import (
    analyze_paper_section,
    evaluate_article,
    generate_article_section,
    revise_article,
)

# Set up logger
logger = logging.getLogger(__name__)

# Load configuration
config = load_config(config_path="config.yaml", logger=logger)


def evaluator_optimizer_loop(
    pdf_images: list, initial_article: str, analysis: str, section: str, max_iterations: int | None = None, is_whole_article: bool = False
) -> str:
    """Execute Evaluator-Optimizer workflow loop.

    This function implements the evaluation-improvement cycle:
    1. Evaluate current article
    2. If pass: return article
    3. If fail: get feedback, revise article, repeat

    Args:
        pdf_images (list): List of base64-encoded PDF page images
        initial_article (str): Initial article generated by article writer
        analysis (str): Analysis result from paper analyzer (for reference)
        section (str): Section name being processed (for logging)
        max_iterations (int, optional): Maximum number of evaluation cycles.
                                       If None, uses config value.
        is_whole_article (bool, optional): If True, use whole article evaluation settings. Defaults to False.

    Returns:
        str: Final article (either passed evaluation or reached max iterations)
    """
    if max_iterations is None:
        workflow_config = config.get("workflow", {})
        if is_whole_article:
            evaluator_config = workflow_config.get("whole_article_evaluator", {})
        else:
            evaluator_config = workflow_config.get("evaluator", {})
        max_iterations = evaluator_config.get("max_iterations", 3)
    
    # Get early exit threshold from config
    workflow_config = config.get("workflow", {})
    if is_whole_article:
        evaluator_config = workflow_config.get("whole_article_evaluator", {})
    else:
        evaluator_config = workflow_config.get("evaluator", {})
    early_exit_threshold = evaluator_config.get("early_exit_threshold", 8)

    current_article = initial_article
    iteration = 0

    logger.info("Starting Evaluator-Optimizer loop (max iterations: %d, whole_article: %s)", max_iterations, is_whole_article)

    while iteration < max_iterations:
        iteration += 1
        logger.info("Evaluation iteration %d/%d", iteration, max_iterations)

        # Phase 3a: Evaluate article
        evaluation = evaluate_article(pdf_images, current_article, analysis, section=section, iteration=iteration, is_whole_article=is_whole_article)

        # Check if article passes evaluation
        if evaluation.pass_evaluation:
            logger.info("Article passed evaluation on iteration %d", iteration)
            logger.info("Scores: accuracy=%d, readability=%d, completeness=%d, style=%d, compliance=%d",
                       evaluation.score.accuracy, evaluation.score.readability, evaluation.score.completeness,
                       evaluation.score.style, evaluation.score.compliance)
            return current_article
        
        # Check for early exit based on score threshold
        min_score = min(
            evaluation.score.accuracy,
            evaluation.score.readability,
            evaluation.score.completeness,
            evaluation.score.style,
            evaluation.score.compliance
        )
        if min_score >= early_exit_threshold:
            logger.info("Early exit: All scores >= %d (iteration %d)", early_exit_threshold, iteration)
            logger.info("Scores: accuracy=%d, readability=%d, completeness=%d, style=%d, compliance=%d",
                       evaluation.score.accuracy, evaluation.score.readability, evaluation.score.completeness,
                       evaluation.score.style, evaluation.score.compliance)
            return current_article

        # Article failed evaluation - get feedback and revise
        feedback = evaluation.feedback
        logger.info("Article failed evaluation. Feedback: %s", feedback)
        logger.info("Scores: accuracy=%d, readability=%d, completeness=%d, style=%d, compliance=%d",
                   evaluation.score.accuracy, evaluation.score.readability, evaluation.score.completeness,
                   evaluation.score.style, evaluation.score.compliance)

        # Phase 3b: Revise article based on feedback
        current_article = revise_article(pdf_images, current_article, feedback, analysis, section=section, iteration=iteration, is_whole_article=is_whole_article)
        logger.info("Article revised based on feedback")

    # Max iterations reached
    logger.warning("Max iterations (%d) reached without passing evaluation", max_iterations)
    logger.info("Returning final version of article")
    return current_article


def process_section_with_workflow(pdf_images: list, section: str, context: str = "") -> tuple:
    """Process a single section using the complete AI workflow.

    This function implements the full Prompt-Chaining workflow:
    Phase 1: Paper Analysis - Extract important information from paper
    Phase 2: Article Generation - Generate article based on analysis
    Phase 3: Evaluation & Improvement - Evaluator-Optimizer loop

    Args:
        pdf_images (list): List of base64-encoded PDF page images
        section (str): Section name to process
        context (str, optional): Context from previous sections. Defaults to "".

    Returns:
        tuple: (analysis_result, final_article)
               - analysis_result: Extracted information from paper
               - final_article: Final article text (passed evaluation or max iterations)
    """
    logger.info("=" * 60)
    logger.info("Processing section with AI workflow: %s", section)
    logger.info("=" * 60)

    # Phase 1: Paper Analysis (論文読む係のLLM)
    logger.info("Phase 1: Paper Analysis")
    analysis = analyze_paper_section(pdf_images, section)
    logger.info("Paper analysis completed for section: %s", section)

    # Phase 2: Article Generation (記事書く係のLLM)
    logger.info("Phase 2: Article Generation")
    initial_article = generate_article_section(pdf_images, section, analysis, context)
    logger.info("Initial article generated for section: %s", section)

    # Phase 3: Evaluation & Improvement (評価用LLM + Evaluator-Optimizer)
    logger.info("Phase 3: Evaluation & Improvement Loop")
    final_article = evaluator_optimizer_loop(pdf_images, initial_article, analysis, section=section)
    logger.info("Final article ready for section: %s", section)

    logger.info("=" * 60)
    logger.info("Workflow completed for section: %s", section)
    logger.info("=" * 60)

    return analysis, final_article


def generate_detailed_summary_with_workflow(pdf_images: list, sections: list) -> tuple:
    """Generate detailed summary and section headings for all sections using AI workflow.

    This is the main entry point for generating detailed summaries.
    It processes each section sequentially using the workflow and
    chains the context forward. After combining all sections, it runs
    a final evaluation-improvement loop on the whole article, followed
    by heading generation for each section.

    Args:
        pdf_images (list): List of base64-encoded PDF page images
        sections (list): List of section names to process

    Returns:
        tuple: (final_summary, section_headings, article_title)
               - final_summary: Complete detailed summary with all sections
               - section_headings: Dictionary mapping section names to generated headings
               - article_title: Generated title for the article
    """
    logger.info("Starting detailed summary generation with AI workflow")
    logger.info("Sections to process: %s", sections)

    detailed_summary = ""
    context = ""
    all_analysis = ""  # Collect all analysis results for whole article evaluation
    section_contents = {}  # Store each section's content for heading generation

    # Process each section individually
    for section in sections:
        # Process section with workflow
        analysis, article = process_section_with_workflow(pdf_images, section, context)

        # Collect analysis results
        all_analysis += f"\n\n## {section}\n\n{analysis}"

        # Add to detailed summary
        detailed_summary += f"\n\n## {section}\n\n{article}"

        # Store section content for heading generation
        section_contents[section] = article

        # Update context for next section (Prompt-Chaining)
        context = detailed_summary

        logger.info("Section '%s' added to detailed summary", section)

    logger.info("All sections processed. Starting whole article evaluation.")

    # Phase 4: Whole Article Evaluation & Improvement
    logger.info("=" * 60)
    logger.info("Phase 4: Whole Article Evaluation & Improvement")
    logger.info("=" * 60)

    final_summary = evaluator_optimizer_loop(
        pdf_images=pdf_images,
        initial_article=detailed_summary,
        analysis=all_analysis,
        section="whole_article",
        is_whole_article=True
    )

    logger.info("=" * 60)
    logger.info("Whole article evaluation completed")
    logger.info("=" * 60)

    # Phase 5: Section Heading Generation
    logger.info("=" * 60)
    logger.info("Phase 5: Section Heading Generation")
    logger.info("=" * 60)

    from src.utils.openai import generate_section_heading

    section_headings = {}
    for section in sections:
        heading = generate_section_heading(section, section_contents[section])
        section_headings[section] = heading
        logger.info("Generated heading for '%s': %s", section, heading)

    logger.info("=" * 60)
    logger.info("Heading generation completed")
    logger.info("=" * 60)

    # Replace fixed section names with generated headings in final summary
    logger.info("Replacing section names with generated headings in final summary")
    for section in sections:
        generated_heading = section_headings.get(section)
        if generated_heading:
            old_heading = f"## {section}"
            new_heading = f"## {generated_heading}"
            final_summary = final_summary.replace(old_heading, new_heading)
            logger.info("Replaced '%s' with '%s'", section, generated_heading)
        else:
            logger.warning("No heading generated for section '%s', keeping original name", section)

    logger.info("Section heading replacement completed")

    # Phase 6: Article Title Generation
    logger.info("=" * 60)
    logger.info("Phase 6: Article Title Generation")
    logger.info("=" * 60)

    from src.utils.openai import generate_article_title

    article_title = generate_article_title(final_summary)
    logger.info("Generated article title: %s", article_title)

    logger.info("=" * 60)
    logger.info("Title generation completed")
    logger.info("=" * 60)

    logger.info("Detailed summary generation completed")
    return final_summary, section_headings, article_title
